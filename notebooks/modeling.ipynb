{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68efdd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fraud = pd.read_csv(\"../data/processed/fraud_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8c757",
   "metadata": {},
   "source": [
    "# Define target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855f6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fraud.drop(columns=['class'])\n",
    "y = fraud['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e5287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['user_id', 'device_id', 'ip_address'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f497d3c",
   "metadata": {},
   "source": [
    "# Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102ee1e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.3 GiB for an array with shape (151112, 151112) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:214\u001b[39m, in \u001b[36mget_dummies\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    210\u001b[39m     with_dummies = [data.select_dtypes(exclude=dtypes_to_encode)]\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode.items(), prefix, prefix_sep):\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     dummy = \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     with_dummies.append(dummy)\n\u001b[32m    224\u001b[39m result = concat(with_dummies, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:353\u001b[39m, in \u001b[36m_get_dummies_1d\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    352\u001b[39m     dummy_dtype = np.bool_\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m dummy_mat = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m dummy_mat[np.arange(\u001b[38;5;28mlen\u001b[39m(codes)), codes] = \u001b[32m1\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[32m    357\u001b[39m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 21.3 GiB for an array with shape (151112, 151112) and data type bool"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974081fb",
   "metadata": {},
   "source": [
    "# Train-test split (MANDATORY: stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5db7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced8e38",
   "metadata": {},
   "source": [
    "# Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27211cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m      3\u001b[39m smote = SMOTE(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      4\u001b[39m X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693805c",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b3832",
   "metadata": {},
   "source": [
    "# Evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b293cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_pr = average_precision_score(y_test, y_prob)\n",
    "\n",
    "f1, auc_pr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b769e0",
   "metadata": {},
   "source": [
    "# Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb26d3",
   "metadata": {},
   "source": [
    "# Evaluate ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac77d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "auc_pr_rf = average_precision_score(y_test, y_prob_rf)\n",
    "\n",
    "f1_rf, auc_pr_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d03628",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f1262",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    rf,\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    scoring='f1',\n",
    "    cv=cv\n",
    ")\n",
    "\n",
    "cv_scores.mean(), cv_scores.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3e18b",
   "metadata": {},
   "source": [
    "# Model comparison & selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91abbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
    "    \"F1 Score\": [f1, f1_rf],\n",
    "    \"AUC-PR\": [auc_pr, auc_pr_rf]\n",
    "})\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
